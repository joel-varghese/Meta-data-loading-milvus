{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e98cd3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from scipy.sparse import csr_matrix\n",
    "from pymilvus import MilvusClient\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00240293",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joeljvarghese/Documents/Workspace/Milvus_ollama_trial/.venv/lib/python3.12/site-packages/milvus_lite/__init__.py:15: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import DistributionNotFound, get_distribution\n",
      "Some parameters are on the meta device because they were offloaded to the disk.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "\n",
    "mc = MilvusClient(\"milvus_demo.db\")\n",
    "\n",
    "model_name = \"BAAI/bge-large-en-v1.5\"\n",
    "DEVICE = torch.device('cuda:3' if torch.cuda.is_available() else 'cpu')\n",
    "encoder = SentenceTransformer(model_name, device=DEVICE)\n",
    "\n",
    "base_model = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "llm = AutoModelForCausalLM.from_pretrained(base_model, device_map=\"auto\")\n",
    "\n",
    "def embed_texts(batch_texts):\n",
    "    embeddings = encoder.encode(\n",
    "        batch_texts,\n",
    "        convert_to_tensor=True,\n",
    "        normalize_embeddings=True,\n",
    "        show_progress_bar=False\n",
    "    )\n",
    "    batch_embeddings = embeddings.cpu().numpy().astype(np.float32)\n",
    "    return batch_embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47ab304",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220e5eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import pandas as pd\n",
    "\n",
    "def convert_row_to_triplets(row):\n",
    "    job_title = row[\"job_title\"]\n",
    "    category = row[\"category\"]\n",
    "    description = row[\"job_description\"]\n",
    "\n",
    "    try:\n",
    "        skills = ast.literal_eval(row[\"job_sill_set\"])\n",
    "    except:\n",
    "        skills = []\n",
    "\n",
    "    triplets = []\n",
    "    for skill in skills:\n",
    "        triplets.append([job_title, \"requires skill\", skill])\n",
    "        triplets.append([job_title, \"provides expertise in\", skill])\n",
    "\n",
    "    triplets.append([job_title, \"is categorized under\", category])\n",
    "\n",
    "    triplets.append([job_title, \"is described as\", description[:200] + \"...\"])\n",
    "\n",
    "    return {\n",
    "        \"passage\": description,\n",
    "        \"triplets\": triplets\n",
    "    }\n",
    "\n",
    "df = pd.read_csv(\"data/all_job_post.csv\")\n",
    "nano_dataset = [convert_row_to_triplets(row) for _, row in df.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57be81e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "entityid_2_relationids = defaultdict(list)\n",
    "relationid_2_passageids = defaultdict(list)\n",
    "\n",
    "entities = []\n",
    "entity2id = {}\n",
    "relations = []\n",
    "relation2id = {}\n",
    "passages = []\n",
    "\n",
    "for passage_id, dataset_info in enumerate(nano_dataset):\n",
    "    passage, triplets = dataset_info[\"passage\"], dataset_info[\"triplets\"]\n",
    "    passages.append(passage)\n",
    "\n",
    "    for subj, _, obj in triplets:\n",
    "        if subj not in entity2id:\n",
    "            entity2id[subj] = len(entities)\n",
    "            entities.append(subj)\n",
    "        subj_id = entity2id[subj]\n",
    "\n",
    "        if obj not in entity2id:\n",
    "            entity2id[obj] = len(entities)\n",
    "            entities.append(obj)\n",
    "        obj_id = entity2id[obj]\n",
    "\n",
    "        relation = \" \".join([subj, _, obj])\n",
    "        if relation not in relation2id:\n",
    "            relation2id[relation] = len(relations)\n",
    "            relations.append(relation)\n",
    "        relation_id = relation2id[relation]\n",
    "\n",
    "        entityid_2_relationids[subj_id].append(relation_id)\n",
    "        entityid_2_relationids[obj_id].append(relation_id)  \n",
    "        relationid_2_passageids[relation_id].append(passage_id)      \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2831b2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = encoder.get_sentence_embedding_dimension()\n",
    "\n",
    "def create_milvus_collection(collection_name: str):\n",
    "    if mc.has_collection(collection_name=collection_name):\n",
    "        mc.drop_collection(collection_name=collection_name)\n",
    "    mc.create_collection(\n",
    "        collection_name=collection_name,\n",
    "        dimension=embedding_dim\n",
    "    )\n",
    "\n",
    "entity_col_name = \"entity_collection\"\n",
    "relation_col_name = \"relation_collection\"\n",
    "passage_col_name = \"passage_collection\"\n",
    "\n",
    "create_milvus_collection(entity_col_name)\n",
    "create_milvus_collection(relation_col_name)\n",
    "create_milvus_collection(passage_col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337cf6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def milvus_insert(\n",
    "    collection_name: str,\n",
    "    text_list: list[str],\n",
    "):\n",
    "    batch_size = embedding_dim\n",
    "    for start in tqdm(range(0, len(text_list), batch_size), desc=\"Inserting {collection_name}\"):\n",
    "        end = start + batch_size\n",
    "        batch_texts = text_list[start : end]\n",
    "        batch_embeddings = embed_texts(batch_texts)\n",
    "\n",
    "        batch_ids = list(range(start,end))\n",
    "        batch_data = [\n",
    "            {\n",
    "                \"id\": id_,\n",
    "                \"text\": text,\n",
    "                \"vector\": vector,\n",
    "            }\n",
    "            for id_, text, vector in zip(batch_ids, batch_texts, batch_embeddings)\n",
    "        ]\n",
    "        mc.insert(\n",
    "            collection_name=collection_name,\n",
    "            data=batch_data,\n",
    "        )\n",
    "\n",
    "\n",
    "milvus_insert(\n",
    "    collection_name=relation_col_name,\n",
    "    text_list=relations,\n",
    ")\n",
    "\n",
    "milvus_insert(\n",
    "    collection_name=entity_col_name,\n",
    "    text_list=entities,\n",
    ")\n",
    "\n",
    "milvus_insert(\n",
    "    collection_name=passage_col_name,\n",
    "    text_list=passages,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f53c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What skills does a Engineer need ?\"\n",
    "\n",
    "query_ner_list = [\"IT\"]\n",
    "\n",
    "query_ner_embeddings = [\n",
    "    embed_texts(query_ner) for query_ner in query_ner_list\n",
    "]\n",
    "\n",
    "top_k = 3\n",
    "\n",
    "entity_search_res = mc.search(\n",
    "    collection_name=\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Milvus_ollama_trial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
