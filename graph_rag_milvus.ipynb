{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e98cd3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from scipy.sparse import csr_matrix\n",
    "from pymilvus import MilvusClient\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00240293",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joeljvarghese/Documents/Workspace/Milvus_ollama_trial/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/joeljvarghese/Documents/Workspace/Milvus_ollama_trial/.venv/lib/python3.12/site-packages/milvus_lite/__init__.py:15: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import DistributionNotFound, get_distribution\n",
      "Some parameters are on the meta device because they were offloaded to the disk.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "\n",
    "mc = MilvusClient(\"milvus_demo.db\")\n",
    "\n",
    "model_name = \"BAAI/bge-large-en-v1.5\"\n",
    "DEVICE = torch.device('cuda:3' if torch.cuda.is_available() else 'cpu')\n",
    "encoder = SentenceTransformer(model_name, device=DEVICE)\n",
    "\n",
    "base_model = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "llm = AutoModelForCausalLM.from_pretrained(base_model, device_map=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
    "\n",
    "def embed_texts(batch_texts):\n",
    "    embeddings = encoder.encode(\n",
    "        batch_texts,\n",
    "        convert_to_tensor=True,\n",
    "        normalize_embeddings=True,\n",
    "        show_progress_bar=False\n",
    "    )\n",
    "    batch_embeddings = embeddings.cpu().numpy().astype(np.float32)\n",
    "    return batch_embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "220e5eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import pandas as pd\n",
    "\n",
    "def convert_row_to_triplets(row):\n",
    "    job_title = row[\"job_title\"]\n",
    "    category = row[\"category\"]\n",
    "    description = row[\"job_description\"]\n",
    "\n",
    "    try:\n",
    "        skills = ast.literal_eval(row[\"job_sill_set\"])\n",
    "    except:\n",
    "        skills = []\n",
    "\n",
    "    triplets = []\n",
    "    for skill in skills:\n",
    "        triplets.append([job_title, \"requires skill\", skill])\n",
    "        triplets.append([job_title, \"provides expertise in\", skill])\n",
    "\n",
    "    triplets.append([job_title, \"is categorized under\", category])\n",
    "\n",
    "    triplets.append([job_title, \"is described as\", description[:200] + \"...\"])\n",
    "\n",
    "    return {\n",
    "        \"passage\": description,\n",
    "        \"triplets\": triplets\n",
    "    }\n",
    "\n",
    "df = pd.read_csv(\"data/all_job_post.csv\")\n",
    "nano_dataset = [convert_row_to_triplets(row) for _, row in df.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57be81e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "entityid_2_relationids = defaultdict(list)\n",
    "relationid_2_passageids = defaultdict(list)\n",
    "\n",
    "entities = []\n",
    "entity2id = {}\n",
    "relations = []\n",
    "relation2id = {}\n",
    "passages = []\n",
    "\n",
    "for passage_id, dataset_info in enumerate(nano_dataset):\n",
    "    passage, triplets = dataset_info[\"passage\"], dataset_info[\"triplets\"]\n",
    "    passages.append(passage)\n",
    "\n",
    "    for subj, _, obj in triplets:\n",
    "        if subj not in entity2id:\n",
    "            entity2id[subj] = len(entities)\n",
    "            entities.append(subj)\n",
    "        subj_id = entity2id[subj]\n",
    "\n",
    "        if obj not in entity2id:\n",
    "            entity2id[obj] = len(entities)\n",
    "            entities.append(obj)\n",
    "        obj_id = entity2id[obj]\n",
    "\n",
    "        relation = \" \".join([subj, _, obj])\n",
    "        if relation not in relation2id:\n",
    "            relation2id[relation] = len(relations)\n",
    "            relations.append(relation)\n",
    "        relation_id = relation2id[relation]\n",
    "\n",
    "        entityid_2_relationids[subj_id].append(relation_id)\n",
    "        entityid_2_relationids[obj_id].append(relation_id)  \n",
    "        relationid_2_passageids[relation_id].append(passage_id)      \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2831b2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = encoder.get_sentence_embedding_dimension()\n",
    "\n",
    "def create_milvus_collection(collection_name: str):\n",
    "    if mc.has_collection(collection_name=collection_name):\n",
    "        mc.drop_collection(collection_name=collection_name)\n",
    "    mc.create_collection(\n",
    "        collection_name=collection_name,\n",
    "        dimension=embedding_dim\n",
    "    )\n",
    "\n",
    "entity_col_name = \"entity_collection\"\n",
    "relation_col_name = \"relation_collection\"\n",
    "passage_col_name = \"passage_collection\"\n",
    "\n",
    "create_milvus_collection(entity_col_name)\n",
    "create_milvus_collection(relation_col_name)\n",
    "create_milvus_collection(passage_col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "337cf6eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inserting {collection_name}: 100%|██████████| 2/2 [02:39<00:00, 79.82s/it]\n",
      "Inserting {collection_name}: 100%|██████████| 2/2 [02:11<00:00, 65.77s/it]\n",
      "Inserting {collection_name}: 100%|██████████| 2/2 [16:11<00:00, 485.81s/it]\n"
     ]
    }
   ],
   "source": [
    "def milvus_insert(\n",
    "    collection_name: str,\n",
    "    text_list: list[str],\n",
    "):\n",
    "    batch_size = embedding_dim\n",
    "    for start in tqdm(range(0, len(text_list), batch_size), desc=\"Inserting {collection_name}\"):\n",
    "        end = start + batch_size\n",
    "        batch_texts = text_list[start : end]\n",
    "        batch_embeddings = embed_texts(batch_texts)\n",
    "\n",
    "        batch_ids = list(range(start,end))\n",
    "        batch_data = [\n",
    "            {\n",
    "                \"id\": id_,\n",
    "                \"text\": text,\n",
    "                \"vector\": vector,\n",
    "            }\n",
    "            for id_, text, vector in zip(batch_ids, batch_texts, batch_embeddings)\n",
    "        ]\n",
    "        mc.insert(\n",
    "            collection_name=collection_name,\n",
    "            data=batch_data,\n",
    "        )\n",
    "\n",
    "\n",
    "milvus_insert(\n",
    "    collection_name=relation_col_name,\n",
    "    text_list=relations,\n",
    ")\n",
    "\n",
    "milvus_insert(\n",
    "    collection_name=entity_col_name,\n",
    "    text_list=entities,\n",
    ")\n",
    "\n",
    "milvus_insert(\n",
    "    collection_name=passage_col_name,\n",
    "    text_list=passages,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7f53c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What skills does an Engineer need ?\"\n",
    "\n",
    "query_ner_list = [\"Engineer\"]\n",
    "\n",
    "query_ner_embeddings = [\n",
    "    embed_texts(query_ner) for query_ner in query_ner_list\n",
    "]\n",
    "\n",
    "top_k = 3\n",
    "\n",
    "entity_search_res = mc.search(\n",
    "    collection_name=entity_col_name,\n",
    "    data=query_ner_embeddings,\n",
    "    anns_field=\"vector\",\n",
    "    search_params={\"metric_type\":\"COSINE\",\"params\": {\"nprobe\":10}},\n",
    "    limit=top_k,\n",
    "    output_fields=[\"id\", \"text\"]\n",
    ")\n",
    "\n",
    "query_embedding = embed_texts([query])\n",
    "\n",
    "relation_search_res = mc.search(\n",
    "    collection_name=relation_col_name,\n",
    "    data=query_embedding,\n",
    "    anns_field=\"vector\",\n",
    "    search_params={\"metric_type\":\"COSINE\",\"params\": {\"nprobe\":10}},\n",
    "    limit=top_k,\n",
    "    output_fields=[\"id\", \"text\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8e1139a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Entity: Engineer\n",
      "868, Score: 0.7559, Sales Engineer\n",
      "392, Score: 0.7442, Information Technology Engineer\n",
      "1009, Score: 0.7119, Technical Sales and Proposal Engineer \n",
      "Relation search results\n",
      "325, Score: 0.6050, Information Technology Infrastructure Engineer is described as JOB TITLE- IT INFRASTRUCTURE ENGINEERLOCATION- DEVENS, MADIRECT CLIENT\n",
      "\"MUST HAVE LIST:\n",
      "10+ YEARS OF EXPERIENCE WITH THE FOLLOWING:• KNOWLEDGE OF DATA CENTER OPERATION AND IT INFRASTRUCTURE.• KNOWLEDG...\n",
      "383, Score: 0.5971, Information Technology Operations Engineer is described as MUST HAVES:\n",
      "5+ YEARS OF EXPERIENCE WITHIN THE ITSM SPACE SPECIFICALLY HANDLING PRODUCTION READINESS ISSUES AND AREASHANDS ONE EXPERIENCE CREATING PRODUCTION READINESS REVIEWS (PRR) OR CHECKLISTS TO DO...\n",
      "391, Score: 0.5899, Information Technology Engineer is described as IT ENGINEER - BOCA RATON, FL - ONSITE \n",
      "SUMMARY:THE IT ENGINEER WILL BE RESPONSIBLE FOR MANAGING AND PROVIDING DIRECT HANDS-ON SUPPORT TO ALL OF OUR LOCATIONS. THE INDIVIDUAL WILL MANAGE AND SUPPORT NE...\n"
     ]
    }
   ],
   "source": [
    "for i, hits in enumerate(entity_search_res):\n",
    "    print(f\"Query Entity: {query_ner_list[i]}\")\n",
    "    for hit in hits:\n",
    "        print(f\"{hit.id}, Score: {hit.score:.4f}, {hit.entity.get('text')}\")\n",
    "\n",
    "print(\"Relation search results\")\n",
    "for hit in relation_search_res[0]:\n",
    "    print(f\"{hit.id}, Score: {hit.score:.4f}, {hit.entity.get('text')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5962ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# col=[\"entity_collection\", \"relation_collection\", \"passage_collection\"]\n",
    "# for name in col:\n",
    "#     if mc.has_collection(collection_name=name):\n",
    "#         mc.drop_collection(collection_name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07426754",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_relation_hits = relation_search_res[0]\n",
    "context_passages = [hit.entity.get(\"text\") for hit in top_relation_hits]\n",
    "context_text = \"\\n\\n\".join(context_passages)\n",
    "\n",
    "entity_names = [hit.entity.get(\"text\") for hits in entity_search_res for hit in hits]\n",
    "context_text = \"Related roles: \" + \", \".join(entity_names) + \"\\n\\n\" + context_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5410e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(prompt, max_new_tokens=256, temperature=0.7):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(llm.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = llm.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            temperature=temperature,\n",
    "            do_sample=True,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "\n",
    "    result = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return result    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad18ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"You are an AI assistant analyzing job data.\n",
    "Summarize the following information into:\n",
    "1. A concise summary\n",
    "2. A bullet list of skills\n",
    "\n",
    "Context:\n",
    "Engineers are responsible for managing and providing direct hands-on support...\n",
    "\"\"\"\n",
    "\n",
    "response = generate_text(prompt)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Milvus_ollama_trial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
